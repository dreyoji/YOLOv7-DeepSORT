{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "\n",
    "In this activity, we will be updating our previous object detection model to YOLOv7 and integrating it with DeepSORT for optimization. The goal is to analyze the impact of the optimization algorithm on the model results and compare the performance of the updated models with the previous ones. We will be using the same dataset as before, but this time we will train the models using time frames ranging from 5 PM to 8 PM. We will be creating three versions of the model - **_small, medium, and large_ - and evaluating their performance using metrics such as F1 curve, P curve, mAP (mean average precision), accuracy, precision, and recall.**\n",
    "\n",
    "To ensure a fair comparison, we will use the same dataset for each model and evaluate their performance separately. We will create a confusion matrix for each model and compare their accuracy, precision, and recall. We will also visualize the training progress of each model using time series graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                    # For deep learning\n",
    "import os                                       # For operating system related tasks \n",
    "import urllib.request                           # For opening and reading URLs\n",
    "import glob                                     # For file handling\n",
    "import shutil                                   # For file operations\n",
    "from IPython.display import Image, clear_output # For displaying images and clearing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch version: 2.1.2+cu118 on device: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Determine the device that PyTorch is using\n",
    "device = torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'\n",
    "\n",
    "# Print the setup information\n",
    "print(f\"Setup complete. Using torch version: {torch.__version__} on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download YOLOv7 repository and install requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download YOLOv7 repository and install requirements\n",
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "%cd yolov7\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yolov7_training.pt', <http.client.HTTPMessage at 0x1ecea4c0850>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the weights file from the URL and save it to the current directory\n",
    "url = \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\"\n",
    "filename = \"yolov7_training.pt\"\n",
    "\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset (Robotflow)\n",
    "\n",
    "Roboflow offers an API to export datasets, and in this case, the YOLOv8 format is used at this [URL](https://app.roboflow.com/data-science-3-5kybl/helmet-detection-lcyce/1).\n",
    "\n",
    "![](https://i.imgur.com/ScfGIey.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow                       \n",
    "\n",
    "from roboflow import Roboflow                   # For downloading the dataset\n",
    "rf = Roboflow(api_key=\"weuUhM15xraEmLMEAiPU\")\n",
    "project = rf.workspace(\"data-science-3-5kybl\").project(\"helmet-detection-lcyce\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train YOLOv7 model with Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the training script with the downloaded dataset and the weights file we downloaded earlier\n",
    "!python train.py \\\n",
    "    --batch 64 \\\n",
    "    --epochs 50 \\\n",
    "    --img-size 640 \\\n",
    "    --data /Helmet-Detection-1/data.yaml \\\n",
    "    --weights 'yolov7_training.pt' \\\n",
    "    --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute evaluation\n",
    "!python detect.py \\\n",
    "    --weights runs/train/exp/weights/best.pt \\\n",
    "    --conf 0.1 \\\n",
    "    --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum images to print\n",
    "limit = 10 \n",
    "\n",
    "# Loop through each image in the directory\n",
    "for i, imageName in enumerate(glob.glob('/yolov7/runs/detect/exp/*.jpg')):\n",
    "    if i >= limit: # Stop if limit is reached\n",
    "        break\n",
    "    display(Image(filename=imageName)) # Display image\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.1. TensorFlow\n",
    "\n",
    "To monitor the training progress and visualize the logs, you can start TensorBoard and launch it after you have started training. The logs are saved in the `runs` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard within the notebook using magics\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.2. DeepSort\n",
    "\n",
    "To detect and track objects in videos or live camera feeds combines with YOLOv7 model. This can be useful in various applications such as surveillance, autonomous vehicles, and object recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/deshwalmahesh/yolov7-deepsort-tracking\n",
    "%cd yolov7-deepsort-tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the trained weights to the current directory and rename it\n",
    "source_file = '/yolov7/runs/train/exp/weights/best.pt'\n",
    "destination_file = 'yolov7x.pt'\n",
    "\n",
    "shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ensure to modify the specified lines in the following Python files before executing this code:\n",
    "\n",
    "- Modify Line `247` in yolov7-deepsort/tracking_helpers.py to set `classes = ['Full_Face','Half_Face','Invalid']`\n",
    "- Modify Line `15` in yolov7-deepsort/data/coco.yml to set `classes = ['Full_Face','Half_Face','Invalid']` \n",
    "- Modify Line `12` to set `nc: 3`\n",
    "\n",
    "After making these changes, you can proceed with running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_helpers import *                 # For detection related functions\n",
    "from tracking_helpers import *                  # For tracking related functions\n",
    "from bridge_wrapper import *                    # For bridge related functions\n",
    "from PIL import Image                           # For image processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detector object\n",
    "detector = Detector() \n",
    "\n",
    "# Set the path to the trained model and load it to the detector object\n",
    "model_path = 'yolov7x.pt' \n",
    "detector.load_model(model_path)\n",
    "\n",
    "# If the result is a 3D array, convert it to an image using OpenCV\n",
    "if len(result.shape) == 3:  \n",
    "    result = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Save the result image to a folder\n",
    "result.save('__path__')\n",
    "\n",
    "# Display the result image\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tracker object with the YOLOv7 model and the ReID model\n",
    "tracker = YOLOv7_DeepSORT(reID_model_path=\"/yolov7/yolov7-deepsort-tracking/deep_sort/model_weights/mars-small128.pb\", detector=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the video and save the result to a file\n",
    "tracker.track_video(\"__path__\", output_folder=\"__path__\", show_live=False, skip_frames=0, count_objects=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Medium Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the training script again with the downloaded dataset but different weights file\n",
    "!python train.py \\\n",
    "    --batch 32 \\\n",
    "    --epochs 75 \\\n",
    "    --img-size 640 \\\n",
    "    --data /Helmet-Detection-1/data.yaml \\\n",
    "    --weights 'yolov7_training.pt' \\\n",
    "    --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute evaluation\n",
    "!python detect.py \\\n",
    "    --weights runs/train/exp/weights/best.pt \\\n",
    "    --conf 0.1 \\\n",
    "    --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum images to print\n",
    "limit = 10 \n",
    "\n",
    "# Loop through each image in the directory\n",
    "for i, imageName in enumerate(glob.glob('/yolov7/runs/detect/exp/*.jpg')):\n",
    "    if i >= limit: # Stop if limit is reached\n",
    "        break\n",
    "    display(Image(filename=imageName)) # Display image\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard within the notebook using magics\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2. DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector() \n",
    "\n",
    "model_path = 'yolov7x.pt' \n",
    "detector.load_model(model_path)\n",
    "\n",
    "if len(result.shape) == 3:  \n",
    "    result = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Save the result image to a folder\n",
    "result.save('__path__')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = YOLOv7_DeepSORT(reID_model_path=\"/yolov7/yolov7-deepsort-tracking/deep_sort/model_weights/mars-small128.pb\", detector=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.track_video(\"__path__\", output_folder=\"__path__\", show_live=False, skip_frames=0, count_objects=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the training script again with the downloaded dataset but different weights file\n",
    "!python train.py \\\n",
    "    --batch 16 \\\n",
    "    --epochs 100 \\\n",
    "    --img-size 640 \\\n",
    "    --data /Helmet-Detection-1/data.yaml \\\n",
    "    --weights 'yolov7_training.pt' \\\n",
    "    --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute evaluation\n",
    "!python detect.py \\\n",
    "    --weights runs/train/exp/weights/best.pt \\\n",
    "    --conf 0.1 \\\n",
    "    --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set maximum images to print\n",
    "limit = 10 \n",
    "\n",
    "# Loop through each image in the directory\n",
    "for i, imageName in enumerate(glob.glob('/yolov7/runs/detect/exp/*.jpg')):\n",
    "    if i >= limit: # Stop if limit is reached\n",
    "        break\n",
    "    display(Image(filename=imageName)) # Display image\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard within the notebook using magics\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2. DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector() \n",
    "\n",
    "model_path = 'yolov7x.pt' \n",
    "detector.load_model(model_path)\n",
    "\n",
    "if len(result.shape) == 3:  \n",
    "    result = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Save the result image to a folder\n",
    "result.save('__path__')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = YOLOv7_DeepSORT(reID_model_path=\"/yolov7/yolov7-deepsort-tracking/deep_sort/model_weights/mars-small128.pb\", detector=detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.track_video(\"__path__\", output_folder=\"__path__\", show_live=False, skip_frames=0, count_objects=True, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
